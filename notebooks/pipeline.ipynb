{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9989a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUCCESS: Fitted preprocessor saved to 'preprocessor.pkl'.\n",
      "This file is ready for deployment alongside your six separate model files.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13332\\2938382985.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Time_Slice'] = data['Time_Slice'].replace('Equilibrium', 2150.0).astype(float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib # Required for saving the pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- 1. Data Loading and Preparation (Preprocessing outside the pipeline) ---\n",
    "\n",
    "# NOTE: This code assumes the 'final.xlsx' file is accessible.\n",
    "data = pd.read_excel('../data/final.xlsx')\n",
    "\n",
    "# Pre-pipeline cleaning: Replace 'Equilibrium' and ensure float type\n",
    "data['Time_Slice'] = data['Time_Slice'].replace('Equilibrium', 2150.0).astype(float)\n",
    "\n",
    "# --- 2. Define Features (X) and Targets (Y) ---\n",
    "\n",
    "TARGET_COLUMNS = ['wheat', 'rice', 'coarse grains', 'protein feed', 'grains', 'four commo-dities']\n",
    "INPUT_FEATURES = [\n",
    "    'BLS Code', 'Scenario', 'Time_Slice', 'CO2 effects', 'CO2 ppm', 'Adaptation'\n",
    "]\n",
    "X_raw = data[INPUT_FEATURES] \n",
    "\n",
    "Y_raw = data[TARGET_COLUMNS]\n",
    "\n",
    "# Perform Train-Test Split (CRUCIAL for fitting only on training data)\n",
    "X_train_raw, X_test_raw, Y_train, Y_test = train_test_split(\n",
    "    X_raw, Y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def predict_single_output(raw_input_data: dict, target_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Transforms raw input data using the preprocessor and runs prediction \n",
    "    using the requested individual model.\n",
    "\n",
    "    Args:\n",
    "        raw_input_data: A dictionary containing the raw feature values \n",
    "                        (e.g., {'BLS Code': 9, 'Scenario': 'GISS', ...}).\n",
    "        target_name: The target column to predict (e.g., 'wheat', 'rice').\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the predicted value.\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "        \n",
    "# --- 3. Pipeline Definition (Your provided structure) ---\n",
    "\n",
    "NOMINAL_OHE_COLS = ['Scenario', 'BLS Code']\n",
    "NUMERIC_SCALER_COL = ['CO2 ppm']\n",
    "# Note: Renamed 'Adaptation' to match the column name in the original data if it was 'Adapt- ation'\n",
    "ORDINAL_ENCODING_COL = ['Adaptation'] \n",
    "BINARY_ENCODING_COL = ['CO2 effects']\n",
    "TIME_SLICE_COL = ['Time_Slice']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # A. Binary Encoding (for 'CO2 effects')\n",
    "        ('co2_binary_encode',\n",
    "         OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore'),\n",
    "         BINARY_ENCODING_COL),\n",
    "\n",
    "        # B. Ordinal Encoding (for 'Adapt- ation')\n",
    "        ('adaptation_ord_encode',\n",
    "         OrdinalEncoder(categories=[['No', 'Level 1', 'Level 2']], handle_unknown='error'),\n",
    "         ORDINAL_ENCODING_COL),\n",
    "\n",
    "        # C. One-Hot Encoding (for 'Scenario', 'BLS Code')\n",
    "        ('nominal_ohe',\n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         NOMINAL_OHE_COLS),\n",
    "\n",
    "        # D. MinMax Scaling (for 'Time_Slice', pre-cleaned)\n",
    "        ('minmax_scale',\n",
    "         MinMaxScaler(),\n",
    "         TIME_SLICE_COL),\n",
    "\n",
    "        # E. Standard Scaling (for 'CO2 ppm')\n",
    "        ('co2_scaler',\n",
    "         StandardScaler(),\n",
    "         NUMERIC_SCALER_COL)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# The final pipeline structure for the preprocessor\n",
    "final_preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "\n",
    "# --- 4. Fit the Pipeline and Export to PKL ---\n",
    "\n",
    "# A. FIT: The pipeline learns all scaling and encoding parameters exclusively from the training data.\n",
    "final_preprocessing_pipeline.fit(X_train_raw)\n",
    "\n",
    "# B. EXPORT: Save the single, fitted pipeline object.\n",
    "pipeline_filename = 'preprocessor.pkl'\n",
    "joblib.dump(final_preprocessing_pipeline, pipeline_filename)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"SUCCESS: Fitted preprocessor saved to '{pipeline_filename}'.\")\n",
    "print(\"This file is ready for deployment alongside your six separate model files.\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38d3ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUCCESS: Fitted preprocessor saved to 'preprocessor.pkl'.\n",
      "This file is ready for deployment alongside your six separate model files.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# B. EXPORT: Save the single, fitted pipeline object.\n",
    "pipeline_filename = 'preprocessor.pkl'\n",
    "joblib.dump(final_preprocessing_pipeline, pipeline_filename)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"SUCCESS: Fitted preprocessor saved to '{pipeline_filename}'.\")\n",
    "print(\"This file is ready for deployment alongside your six separate model files.\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3de555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREPROCESSED X_TRAIN DATA (Features Ready for Model Fitting)\n",
      "============================================================\n",
      "   CO2 effects_Yes  Adaptation  Scenario_CM2-S550  Scenario_CM2-S750  \\\n",
      "0              0.0         1.0                1.0                0.0   \n",
      "1              0.0         0.0                0.0                0.0   \n",
      "2              1.0         0.0                0.0                0.0   \n",
      "3              1.0         2.0                0.0                0.0   \n",
      "4              0.0         1.0                1.0                0.0   \n",
      "\n",
      "   Scenario_CM3-A  Scenario_GFDL  Scenario_GISS  Scenario_UKMO  BLS Code_9  \\\n",
      "0             0.0            0.0            0.0            0.0         0.0   \n",
      "1             0.0            0.0            0.0            1.0         0.0   \n",
      "2             0.0            1.0            0.0            0.0         0.0   \n",
      "3             0.0            0.0            0.0            1.0         0.0   \n",
      "4             0.0            0.0            0.0            0.0         0.0   \n",
      "\n",
      "   BLS Code_10  ...  BLS Code_906  BLS Code_907  BLS Code_908  BLS Code_909  \\\n",
      "0          0.0  ...           0.0           0.0           0.0           0.0   \n",
      "1          0.0  ...           0.0           0.0           0.0           0.0   \n",
      "2          0.0  ...           0.0           0.0           0.0           0.0   \n",
      "3          0.0  ...           0.0           0.0           0.0           0.0   \n",
      "4          0.0  ...           0.0           0.0           0.0           0.0   \n",
      "\n",
      "   BLS Code_910  BLS Code_911  BLS Code_912  BLS Code_913  Time_Slice  \\\n",
      "0           0.0           0.0           0.0           0.0         0.0   \n",
      "1           0.0           0.0           0.0           0.0         1.0   \n",
      "2           0.0           0.0           0.0           0.0         1.0   \n",
      "3           0.0           0.0           0.0           0.0         1.0   \n",
      "4           0.0           0.0           0.0           0.0         0.0   \n",
      "\n",
      "    CO2 ppm  \n",
      "0 -1.062058  \n",
      "1 -1.062058  \n",
      "2  0.924486  \n",
      "3  0.924486  \n",
      "4 -1.062058  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "Shape of processed features: (870, 42)\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Inspect and Display Processed Data ---\n",
    "\n",
    "# A. Transform the training data (output is a NumPy array)\n",
    "X_train_processed = final_preprocessing_pipeline.transform(X_train_raw)\n",
    "\n",
    "# B. Helper function to clean Scikit-learn prefixes for readability\n",
    "def clean_pipeline_feature_names(feature_names):\n",
    "    \"\"\"Removes the Scikit-learn transformer prefixes (e.g., 'ordinal_encode__').\"\"\"\n",
    "    cleaned_names = []\n",
    "    for name in feature_names:\n",
    "        if '__' in name:\n",
    "            cleaned_names.append(name.split('__', 1)[1])\n",
    "        else:\n",
    "            cleaned_names.append(name)\n",
    "    return cleaned_names\n",
    "\n",
    "# C. Get feature names and clean them\n",
    "raw_feature_names = final_preprocessing_pipeline['preprocessor'].get_feature_names_out()\n",
    "final_feature_names = clean_pipeline_feature_names(raw_feature_names)\n",
    "\n",
    "# D. Create the final named DataFrame (x_train_final)\n",
    "x_train_final = pd.DataFrame(X_train_processed, columns=final_feature_names)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREPROCESSED X_TRAIN DATA (Features Ready for Model Fitting)\")\n",
    "print(\"=\" * 60)\n",
    "print(x_train_final.head())\n",
    "print(f\"\\nShape of processed features: {x_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "411a71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Process Test Data (X_test_final)\n",
    "# IMPORTANT: Use the fitted pipeline's .transform(), NOT .fit_transform()\n",
    "X_test_processed = final_preprocessing_pipeline.transform(X_test_raw)\n",
    "x_test = pd.DataFrame(X_test_processed, columns=final_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87b47e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2 effects_Yes</th>\n",
       "      <th>Adaptation</th>\n",
       "      <th>Scenario_CM2-S550</th>\n",
       "      <th>Scenario_CM2-S750</th>\n",
       "      <th>Scenario_CM3-A</th>\n",
       "      <th>Scenario_GFDL</th>\n",
       "      <th>Scenario_GISS</th>\n",
       "      <th>Scenario_UKMO</th>\n",
       "      <th>BLS Code_9</th>\n",
       "      <th>BLS Code_10</th>\n",
       "      <th>...</th>\n",
       "      <th>BLS Code_906</th>\n",
       "      <th>BLS Code_907</th>\n",
       "      <th>BLS Code_908</th>\n",
       "      <th>BLS Code_909</th>\n",
       "      <th>BLS Code_910</th>\n",
       "      <th>BLS Code_911</th>\n",
       "      <th>BLS Code_912</th>\n",
       "      <th>BLS Code_913</th>\n",
       "      <th>Time_Slice</th>\n",
       "      <th>CO2 ppm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.092239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-1.062058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.068065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.062058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.062058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-1.062058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.421228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CO2 effects_Yes  Adaptation  Scenario_CM2-S550  Scenario_CM2-S750  \\\n",
       "0                1.0         1.0                0.0                0.0   \n",
       "1                0.0         1.0                1.0                0.0   \n",
       "2                1.0         1.0                0.0                0.0   \n",
       "3                1.0         1.0                1.0                0.0   \n",
       "4                1.0         1.0                0.0                0.0   \n",
       "..               ...         ...                ...                ...   \n",
       "213              0.0         0.0                0.0                0.0   \n",
       "214              0.0         1.0                0.0                1.0   \n",
       "215              1.0         0.0                0.0                0.0   \n",
       "216              0.0         1.0                0.0                1.0   \n",
       "217              1.0         1.0                1.0                0.0   \n",
       "\n",
       "     Scenario_CM3-A  Scenario_GFDL  Scenario_GISS  Scenario_UKMO  BLS Code_9  \\\n",
       "0               1.0            0.0            0.0            0.0         0.0   \n",
       "1               0.0            0.0            0.0            0.0         0.0   \n",
       "2               0.0            0.0            1.0            0.0         0.0   \n",
       "3               0.0            0.0            0.0            0.0         0.0   \n",
       "4               0.0            0.0            0.0            1.0         0.0   \n",
       "..              ...            ...            ...            ...         ...   \n",
       "213             0.0            1.0            0.0            0.0         0.0   \n",
       "214             0.0            0.0            0.0            0.0         0.0   \n",
       "215             0.0            1.0            0.0            0.0         0.0   \n",
       "216             0.0            0.0            0.0            0.0         0.0   \n",
       "217             0.0            0.0            0.0            0.0         0.0   \n",
       "\n",
       "     BLS Code_10  ...  BLS Code_906  BLS Code_907  BLS Code_908  BLS Code_909  \\\n",
       "0            0.0  ...           0.0           0.0           0.0           0.0   \n",
       "1            0.0  ...           0.0           0.0           0.0           0.0   \n",
       "2            0.0  ...           0.0           0.0           0.0           0.0   \n",
       "3            0.0  ...           0.0           0.0           0.0           0.0   \n",
       "4            0.0  ...           0.0           0.0           0.0           0.0   \n",
       "..           ...  ...           ...           ...           ...           ...   \n",
       "213          0.0  ...           0.0           0.0           0.0           0.0   \n",
       "214          0.0  ...           0.0           0.0           0.0           0.0   \n",
       "215          0.0  ...           0.0           0.0           0.0           0.0   \n",
       "216          0.0  ...           0.0           0.0           0.0           0.0   \n",
       "217          0.0  ...           0.0           0.0           0.0           0.0   \n",
       "\n",
       "     BLS Code_910  BLS Code_911  BLS Code_912  BLS Code_913  Time_Slice  \\\n",
       "0             0.0           0.0           0.0           0.0    0.230769   \n",
       "1             0.0           0.0           0.0           0.0    0.461538   \n",
       "2             0.0           0.0           0.0           0.0    1.000000   \n",
       "3             0.0           0.0           0.0           1.0    0.230769   \n",
       "4             0.0           0.0           0.0           0.0    1.000000   \n",
       "..            ...           ...           ...           ...         ...   \n",
       "213           0.0           0.0           0.0           0.0    1.000000   \n",
       "214           0.0           0.0           0.0           0.0    0.000000   \n",
       "215           0.0           0.0           0.0           0.0    1.000000   \n",
       "216           0.0           0.0           0.0           0.0    0.461538   \n",
       "217           0.0           0.0           0.0           0.0    0.461538   \n",
       "\n",
       "      CO2 ppm  \n",
       "0    1.092239  \n",
       "1   -1.062058  \n",
       "2    0.924486  \n",
       "3    0.068065  \n",
       "4    0.924486  \n",
       "..        ...  \n",
       "213 -1.062058  \n",
       "214 -1.062058  \n",
       "215  0.924486  \n",
       "216 -1.062058  \n",
       "217  0.421228  \n",
       "\n",
       "[218 rows x 42 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0907c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_train.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(x_train_final, 'x_train.pkl')\n",
    "joblib.dump(Y_train, 'y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8348e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(x_test, 'x_test.pkl')\n",
    "joblib.dump(Y_test, 'y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e383582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUCCESS: Fitted preprocessor saved to 'preprocessor.pkl'.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13332\\3857493351.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Time_Slice'] = data['Time_Slice'].replace('Equilibrium', 2150.0).astype(float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib # Required for saving/loading assets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "# --- 1. DATA LOADING AND PREPARATION (FOR FITTING) ---\n",
    "\n",
    "# NOTE: This section runs once to prepare data and fit the preprocessor.\n",
    "try:\n",
    "    data = pd.read_excel('../data/final.xlsx')\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: 'final.xlsx' not found. Skipping fitting phase. Assuming 'preprocessor.pkl' exists.\")\n",
    "    data = pd.DataFrame() # Create empty DataFrame if file is missing, allowing the rest to define assets\n",
    "\n",
    "# Pre-pipeline cleaning: Replace 'Equilibrium' and ensure float type\n",
    "if not data.empty:\n",
    "    data['Time_Slice'] = data['Time_Slice'].replace('Equilibrium', 2150.0).astype(float)\n",
    "\n",
    "# --- 2. DEFINE FEATURES AND TARGETS ---\n",
    "\n",
    "TARGET_COLUMNS = ['wheat', 'rice', 'coarse grains', 'protein feed', 'grains', 'four commo-dities']\n",
    "# Using the correct original feature names:\n",
    "INPUT_FEATURES = [\n",
    "    'BLS Code', 'Scenario', 'Time_Slice', 'CO2 effects', 'CO2 ppm', 'Adaptation'\n",
    "]\n",
    "\n",
    "# --- 3. PIPELINE DEFINITION ---\n",
    "\n",
    "NOMINAL_OHE_COLS = ['Scenario', 'BLS Code']\n",
    "NUMERIC_SCALER_COL = ['CO2 ppm']\n",
    "# CRITICAL FIX: Use the original column name 'Adapt- ation'\n",
    "ORDINAL_ENCODING_COL = ['Adaptation'] \n",
    "BINARY_ENCODING_COL = ['CO2 effects']\n",
    "TIME_SLICE_COL = ['Time_Slice']\n",
    "CATEGORICAL_COLS = ['Scenario', 'CO2 effects', 'Adapt- ation'] \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # A. Binary Encoding (for 'CO2 effects')\n",
    "        ('co2_binary_encode', OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore'), BINARY_ENCODING_COL),\n",
    "\n",
    "        # B. Ordinal Encoding (for 'Adapt- ation')\n",
    "        ('adaptation_ord_encode', OrdinalEncoder(categories=[['No', 'Level 1', 'Level 2']], handle_unknown='error'), ORDINAL_ENCODING_COL),\n",
    "\n",
    "        # C. One-Hot Encoding (for 'Scenario', 'BLS Code')\n",
    "        ('nominal_ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), NOMINAL_OHE_COLS),\n",
    "\n",
    "        # D. MinMax Scaling (for 'Time_Slice')\n",
    "        ('minmax_scale', MinMaxScaler(), TIME_SLICE_COL),\n",
    "\n",
    "        # E. Standard Scaling (for 'CO2 ppm')\n",
    "        ('co2_scaler', StandardScaler(), NUMERIC_SCALER_COL)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# The final pipeline structure for the preprocessor\n",
    "final_preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "\n",
    "# --- 4. FIT AND EXPORT PREPROCESSOR (IF DATA IS AVAILABLE) ---\n",
    "\n",
    "if not data.empty:\n",
    "    X_raw = data[INPUT_FEATURES] \n",
    "    Y_raw = data[TARGET_COLUMNS]\n",
    "    X_train_raw, _, _, _ = train_test_split(X_raw, Y_raw, test_size=0.2, random_state=42)\n",
    "    \n",
    "    final_preprocessing_pipeline.fit(X_train_raw)\n",
    "    pipeline_filename = 'preprocessor.pkl'\n",
    "    joblib.dump(final_preprocessing_pipeline, pipeline_filename)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"SUCCESS: Fitted preprocessor saved to '{pipeline_filename}'.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# --- 5. DEPLOYMENT ASSET LOADING (RUNS ONCE AT SERVER STARTUP) ---\n",
    "\n",
    "# Load the single fitted preprocessor pipeline\n",
    "try:\n",
    "    PREPROCESSOR = joblib.load('preprocessor.pkl')\n",
    "except FileNotFoundError:\n",
    "    print(\"FATAL: Cannot load 'preprocessor.pkl'. Check file path.\")\n",
    "    PREPROCESSOR = None\n",
    "\n",
    "# Load all individual model files into a dictionary\n",
    "MODELS = {}\n",
    "for col in TARGET_COLUMNS:\n",
    "    # Model files are saved using underscores (e.g., model_coarse_grains.pkl)\n",
    "    model_key = col.replace(' ', '_') \n",
    "    model_filename = f'model_{model_key}.pkl'\n",
    "    try:\n",
    "        MODELS[col.replace(' ', '_')] = joblib.load(model_filename)\n",
    "    except FileNotFoundError:\n",
    "        # This is okay if only one model is needed, but warns if a file is missing\n",
    "        pass \n",
    "        # print(f\"Warning: Model file '{model_filename}' not found.\") \n",
    "\n",
    "\n",
    "def predict_single_output(raw_input_data: dict, target_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Transforms raw input data using the preprocessor and runs prediction \n",
    "    using the requested individual model.\n",
    "\n",
    "    Args:\n",
    "        raw_input_data: A dictionary containing the raw feature values.\n",
    "        target_name: The target column to predict (e.g., 'wheat').\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the predicted value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Input Validation and Preparation\n",
    "    target_key = target_name.replace(' ', '_')\n",
    "    if target_key not in MODELS:\n",
    "        return {\"error\": f\"Invalid target key '{target_name}'. Must be one of: {list(MODELS.keys())}\"}\n",
    "    if PREPROCESSOR is None:\n",
    "        return {\"error\": \"Preprocessing asset is not loaded. Server startup failed.\"}\n",
    "    \n",
    "    # Convert the single raw input dictionary into a DataFrame\n",
    "    try:\n",
    "        X_new_raw = pd.DataFrame([raw_input_data])\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to parse raw input data into DataFrame: {e}\"}\n",
    "\n",
    "    # --- FIX: Enforce correct data types for pipeline compatibility ---\n",
    "    \n",
    "    # Enforce float type for scaling components (Time_Slice and CO2 ppm)\n",
    "    for col in TIME_SLICE_COL + NUMERIC_SCALER_COL:\n",
    "        if col in X_new_raw.columns:\n",
    "            try:\n",
    "                # CRITICAL: Convert to float first!\n",
    "                X_new_raw[col] = X_new_raw[col].astype(float)\n",
    "            except Exception:\n",
    "                return {\"error\": f\"Type Error: Failed to convert numerical column '{col}' to float.\"}\n",
    "\n",
    "    # Enforce string/object type for categorical/encoding components\n",
    "    for col in CATEGORICAL_COLS + ORDINAL_ENCODING_COL:\n",
    "        if col in X_new_raw.columns:\n",
    "            # CRITICAL: Convert to string to ensure consistency for encoders\n",
    "            X_new_raw[col] = X_new_raw[col].astype(str)\n",
    "        \n",
    "    # --- END FIX ---\n",
    "\n",
    "    # 2. Preprocessing\n",
    "    # The PREPROCESSOR handles all scaling, encoding, and ordering learned during fit.\n",
    "    try:\n",
    "        # Only pass the 6 defined INPUT_FEATURES to the transformer\n",
    "        X_new_processed = PREPROCESSOR.transform(X_new_raw[INPUT_FEATURES])\n",
    "    except Exception as e:\n",
    "        # Catch errors during transformation (e.g., unknown category not handled)\n",
    "        return {\"error\": f\"An error occurred during transformation in the pipeline. Detail: {e}\"}\n",
    "    \n",
    "    # --- DEBUG LINE ADDED ---\n",
    "    # Print the first 10 processed features for comparison with the GOLD STANDARD\n",
    "    print(f\"\\n[DEBUG] Web Processed Features (First 10): {X_new_processed[0][:10]}\")\n",
    "    # -----------------------\n",
    "    \n",
    "    # 3. Model Selection and Prediction\n",
    "    selected_model = MODELS[target_key]\n",
    "    \n",
    "    # Run prediction on the processed features\n",
    "    raw_prediction = selected_model.predict(X_new_processed)\n",
    "    \n",
    "    # 4. Format Output\n",
    "    predicted_value = raw_prediction[0] # Get the single prediction value\n",
    "    \n",
    "    return {\n",
    "        \"target\": target_name,\n",
    "        \"predicted_yield_change_percent\": round(float(predicted_value), 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f667e5b-cc4d-4588-ad88-eacbd4284c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
